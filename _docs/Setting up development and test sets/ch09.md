---
title: 优化指标和满意度指标
permalink: /docs/ch09/
---

下面我们来了解一下组合多个评估指标的另一种方法。

假设你既关心学习算法的准确率（accuracy），又在意其运行时间（running time），请从下面的三个分类器中做出选择：

| Classifier | Accuracy | Running time |
| ---------- | -------- | ------------ |
| A          | 90%      | 80ms         |
| B          | 92%      | 95ms         |
| C          | 95%      | 1,500ms      |

将准确率和与运行时间放入单个公式计算后可以导出单个的指标，这似乎不太符合常理，例如：

$$
Accuracy - 0.5 * RunningTime
$$

有一种替代方案可供选择：首先定义一个 “可接受的” 运行时间，一般低于 100ms 。接着，在限定的运行时间范围内，尽可能地将分类器的准确率最大化。此时，运行时间代表着 “满意度指标”  —— 你的分类器必须在这个指标上表现得 “足够好” ，这里指的是运行时间约束上限为 100ms；而准确度则代表着 “优化指标”。

如果要考虑 $ N $ 项不同的标准，比如模型的二进制文件大小（这对移动端 app 尤为重要，因为用户不想下载体积很大的 app）、运行时间和准确率，你或许需要设置 $ N-1 $ 个 “满意度” 指标，即先要求它们满足一定的值或范围，下一步才是定义一个 “优化” 指标。例如分别为二进制文件的大小和运行时间设定可接受的阈值，并尝试根据这些限制来优化准确率指标。

最后再举一个例子，假设你正在设计一个硬件设备，该设备可以根据用户设置的特殊 “唤醒词” 来唤醒系统，类似于 Amazon Echo 的监听词为 “Alexa”，苹果（Apple） Siri 的监听词为 “Hey Siri”，安卓（Android） 的监听词为 “Okay Google”，以及百度（Baidu）应用的监听词 “Hello Baidu.” 我们关心的指标是假正例率（false positive rate，又译作假阳率，误诊率）—— 用户没有说出唤醒词，系统却被唤醒了，以及假反例率（false negative rate，又译作假阴率，漏诊率）——用户说出了唤醒词，系统却没能正确被唤醒。这个系统的一个较为合理的优化对象是尝试去最小化假反例率（优化指标），减少用户说出唤醒词而系统却没能正确唤醒的发生率，同时设置约束为每 24 小时不超过一次误报（满意度指标）。

一旦你的团队在优化评估指标上保持一致，他们将能够取得更快的进展。
